The European Commission has proposed a controversial new regulation which would require chat apps, including WhatsApp and Facebook Messenger, to selectively scan users’ private messages for child sexual abuse material and evidence of grooming. Privacy experts have condemned the plans, which were leaked online last month. Ann Cathrin Riedel and Teresa Widlok of think tank LOAD eV, writing in German daily Welt, criticised the proposals. They said: "With the planned chat law, Brussels wants to interfere with citizens' private communication. "If chat control really passes, it would be the most blatant case of warrantless mass surveillance since the NSA affair. Where is the outcry?" In 2013, mobile phone provider Verizon Communications was ordered to turn over all its call records for a three-month period.  It meant the US National Security Agency (NSA) could snoop on calls without suspecting anyone of wrongdoing. Former CIA contractor Edward Snowden leaked details of extensive internet and phone surveillance by American intelligence agencies to the media. After a leak of the EU legislation was shared online, Johns Hopkins cryptography professor Matthew Green tweeted: "This document is the most terrifying thing I’ve ever seen. "It describes the most sophisticated mass surveillance machinery ever deployed outside of China and the USSR. Not an exaggeration."  READ MORE ON THE RAF FLYPAST ROUTE Ms Riedel and Ms Widlok allege that the Commission has presented a draft law which will shake freedom of communication, digital secrecy of correspondence and privacy to the core. They write: "With the intention of preventing child abuse, the EU Commission is creating the most blatant case of mass surveillance since the NSA affair. "Only this time it is not foreign intelligence services spying on us, it is the European Union." The pair add that even child protection agencies say the proposals are disproportionate because of "blanket" scans of private communications, which could see britons have their messaged read.  DON'T MISS: Travel Chaos: BRITISH passengers sensationally blamed for holiday hell [LATEST] Is Monday a bank holiday? When will you head back to work? [REVEALED] Best places to watch RAF Red Arrows flypast for Queen's Jubilee 2022 [REPORT] They slam the plans for lacking detail and how they will work at a technical level, saying there is a fine line between family snaps of children running around naked on a beach and child pornography. The regulation would permit scans for existing child abuse material, but also for new child sexual abuse material or grooming. It would grant surveillance powers to authorities to scan conversations on platforms should they receive a detection order which would use artificial intelligence to scan pictures and texts. Ms Riedel and Ms Widlok add that without a far-reaching obligation to identify all those participating in communications and precise knowledge of the context in which an image is sent, even the best filter or scanner will miss the mark in too many cases.  They argue it is unfair that net activists are accused of being concerned only with privacy and not with the protection of children. The piece continues: "Nobody feels indifferent to the reports of the past few weeks that more and more depictions of abuse are being found on the European part of the internet. "Net activists have therefore been calling for years for abuse depictions that are recognised as such to be deleted, instead of blocking them and merely putting a stop sign on websites. The spread of images once they are on the net can only be stopped by deleting them." They point to the success of a police investigation launched in October 2019 as evidence that authorities are capable of carrying out their work without new powers.  Their op-ed concludes: "The Commission's draft is silent on all this. Instead, it comprehensively questions private communication - and this is the core of our freedom debate. Because our civil liberties are really at risk." The Commission says detection technologies must only be used to detect child sexual abuse and providers will have to deploy the least privacy-intrusive technologies. But Professor Green warned: "By legally mandating the construction of these surveillance systems in Europe, the European government will ultimately make these capabilities available to every government." Joe Mullin, a senior policy analyst at the digital rights group Electronic Frontier Foundation, told CNBC the proposal is incompatible with end-to-end encryption and basic privacy rights. He said: "If it becomes law, the proposal would be a disaster for user privacy not just in the EU but throughout the world." 